{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Xbox Prediction Project\n",
                "This notebook contains the code for loading datasets, preprocessing data, training machine learning models (RandomForestClassifier and LogisticRegression), and evaluating their performance."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import Libraries\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data = pd.read_csv('D:\\\\College_Work\\\\Project\\\\Xbox_Prediction\\\\train.csv')\n",
                "test_data = pd.read_csv('D:\\\\College_Work\\\\Project\\\\Xbox_Prediction\\\\test.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>user</th>\n",
                            "      <th>sku</th>\n",
                            "      <th>category</th>\n",
                            "      <th>query</th>\n",
                            "      <th>click_time</th>\n",
                            "      <th>query_time</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0001cd0d10bbc585c9ba287c963e00873d4c0bfd</td>\n",
                            "      <td>2032076</td>\n",
                            "      <td>abcat0701002</td>\n",
                            "      <td>gears of war</td>\n",
                            "      <td>2011-10-09 17:22:56.101</td>\n",
                            "      <td>2011-10-09 17:21:42.917</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>00033dbced6acd3626c4b56ff5c55b8d69911681</td>\n",
                            "      <td>9854804</td>\n",
                            "      <td>abcat0701002</td>\n",
                            "      <td>Gears of war</td>\n",
                            "      <td>2011-09-25 13:35:42.198</td>\n",
                            "      <td>2011-09-25 13:35:33.234</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>00033dbced6acd3626c4b56ff5c55b8d69911681</td>\n",
                            "      <td>2670133</td>\n",
                            "      <td>abcat0701002</td>\n",
                            "      <td>Gears of war</td>\n",
                            "      <td>2011-09-25 13:36:08.668</td>\n",
                            "      <td>2011-09-25 13:35:33.234</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>00033dbced6acd3626c4b56ff5c55b8d69911681</td>\n",
                            "      <td>9984142</td>\n",
                            "      <td>abcat0701002</td>\n",
                            "      <td>Assassin creed</td>\n",
                            "      <td>2011-09-25 13:37:23.709</td>\n",
                            "      <td>2011-09-25 13:37:00.049</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0007756f015345450f7be1df33695421466b7ce4</td>\n",
                            "      <td>2541184</td>\n",
                            "      <td>abcat0701002</td>\n",
                            "      <td>dead island</td>\n",
                            "      <td>2011-09-11 15:15:34.336</td>\n",
                            "      <td>2011-09-11 15:15:26.206</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                       user      sku      category  \\\n",
                            "0  0001cd0d10bbc585c9ba287c963e00873d4c0bfd  2032076  abcat0701002   \n",
                            "1  00033dbced6acd3626c4b56ff5c55b8d69911681  9854804  abcat0701002   \n",
                            "2  00033dbced6acd3626c4b56ff5c55b8d69911681  2670133  abcat0701002   \n",
                            "3  00033dbced6acd3626c4b56ff5c55b8d69911681  9984142  abcat0701002   \n",
                            "4  0007756f015345450f7be1df33695421466b7ce4  2541184  abcat0701002   \n",
                            "\n",
                            "            query               click_time               query_time  \n",
                            "0    gears of war  2011-10-09 17:22:56.101  2011-10-09 17:21:42.917  \n",
                            "1    Gears of war  2011-09-25 13:35:42.198  2011-09-25 13:35:33.234  \n",
                            "2    Gears of war  2011-09-25 13:36:08.668  2011-09-25 13:35:33.234  \n",
                            "3  Assassin creed  2011-09-25 13:37:23.709  2011-09-25 13:37:00.049  \n",
                            "4     dead island  2011-09-11 15:15:34.336  2011-09-11 15:15:26.206  "
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preprocess Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to\n",
                        "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Package stopwords is already up-to-date!\n",
                        "[nltk_data] Downloading package wordnet to\n",
                        "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Package wordnet is already up-to-date!\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Import Libraries\n",
                "import re\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "import nltk\n",
                "\n",
                "nltk.download('stopwords')\n",
                "nltk.download('wordnet')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tokenize the queries\n",
                "train_data['query'] = [re.findall(r'\\w+', i.lower()) for i in train_data['query'].fillna('NONE')]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove stopwords and digits\n",
                "stopwords_eng = stopwords.words('english')\n",
                "filtered_queries = []\n",
                "for query in train_data['query']:\n",
                "    filtered_query = [word for word in query if word not in stopwords_eng and not word.isdigit()]\n",
                "    filtered_queries.append(filtered_query)\n",
                "train_data['filtered_query'] = filtered_queries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Lemmatize the words\n",
                "lemmatizer = WordNetLemmatizer()\n",
                "lemmatized_queries = []\n",
                "for query in train_data['filtered_query']:\n",
                "    lemmatized_query = [lemmatizer.lemmatize(word, pos=\"v\") for word in query]\n",
                "    lemmatized_queries.append(lemmatized_query)\n",
                "train_data['lemmatized_query'] = [' '.join(query) for query in lemmatized_queries]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>user</th>\n",
                            "      <th>sku</th>\n",
                            "      <th>category</th>\n",
                            "      <th>query</th>\n",
                            "      <th>click_time</th>\n",
                            "      <th>query_time</th>\n",
                            "      <th>filtered_query</th>\n",
                            "      <th>lemmatized_query</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0001cd0d10bbc585c9ba287c963e00873d4c0bfd</td>\n",
                            "      <td>2032076</td>\n",
                            "      <td>abcat0701002</td>\n",
                            "      <td>[gears, of, war]</td>\n",
                            "      <td>2011-10-09 17:22:56.101</td>\n",
                            "      <td>2011-10-09 17:21:42.917</td>\n",
                            "      <td>[gears, war]</td>\n",
                            "      <td>gear war</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>00033dbced6acd3626c4b56ff5c55b8d69911681</td>\n",
                            "      <td>9854804</td>\n",
                            "      <td>abcat0701002</td>\n",
                            "      <td>[gears, of, war]</td>\n",
                            "      <td>2011-09-25 13:35:42.198</td>\n",
                            "      <td>2011-09-25 13:35:33.234</td>\n",
                            "      <td>[gears, war]</td>\n",
                            "      <td>gear war</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>00033dbced6acd3626c4b56ff5c55b8d69911681</td>\n",
                            "      <td>2670133</td>\n",
                            "      <td>abcat0701002</td>\n",
                            "      <td>[gears, of, war]</td>\n",
                            "      <td>2011-09-25 13:36:08.668</td>\n",
                            "      <td>2011-09-25 13:35:33.234</td>\n",
                            "      <td>[gears, war]</td>\n",
                            "      <td>gear war</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>00033dbced6acd3626c4b56ff5c55b8d69911681</td>\n",
                            "      <td>9984142</td>\n",
                            "      <td>abcat0701002</td>\n",
                            "      <td>[assassin, creed]</td>\n",
                            "      <td>2011-09-25 13:37:23.709</td>\n",
                            "      <td>2011-09-25 13:37:00.049</td>\n",
                            "      <td>[assassin, creed]</td>\n",
                            "      <td>assassin creed</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0007756f015345450f7be1df33695421466b7ce4</td>\n",
                            "      <td>2541184</td>\n",
                            "      <td>abcat0701002</td>\n",
                            "      <td>[dead, island]</td>\n",
                            "      <td>2011-09-11 15:15:34.336</td>\n",
                            "      <td>2011-09-11 15:15:26.206</td>\n",
                            "      <td>[dead, island]</td>\n",
                            "      <td>dead island</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                       user      sku      category  \\\n",
                            "0  0001cd0d10bbc585c9ba287c963e00873d4c0bfd  2032076  abcat0701002   \n",
                            "1  00033dbced6acd3626c4b56ff5c55b8d69911681  9854804  abcat0701002   \n",
                            "2  00033dbced6acd3626c4b56ff5c55b8d69911681  2670133  abcat0701002   \n",
                            "3  00033dbced6acd3626c4b56ff5c55b8d69911681  9984142  abcat0701002   \n",
                            "4  0007756f015345450f7be1df33695421466b7ce4  2541184  abcat0701002   \n",
                            "\n",
                            "               query               click_time               query_time  \\\n",
                            "0   [gears, of, war]  2011-10-09 17:22:56.101  2011-10-09 17:21:42.917   \n",
                            "1   [gears, of, war]  2011-09-25 13:35:42.198  2011-09-25 13:35:33.234   \n",
                            "2   [gears, of, war]  2011-09-25 13:36:08.668  2011-09-25 13:35:33.234   \n",
                            "3  [assassin, creed]  2011-09-25 13:37:23.709  2011-09-25 13:37:00.049   \n",
                            "4     [dead, island]  2011-09-11 15:15:34.336  2011-09-11 15:15:26.206   \n",
                            "\n",
                            "      filtered_query lemmatized_query  \n",
                            "0       [gears, war]         gear war  \n",
                            "1       [gears, war]         gear war  \n",
                            "2       [gears, war]         gear war  \n",
                            "3  [assassin, creed]   assassin creed  \n",
                            "4     [dead, island]      dead island  "
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Split Data, Extract Features and Labels, Vectorize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split the data\n",
                "train, test = train_test_split(train_data, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract features and labels\n",
                "train_features = train['lemmatized_query']\n",
                "test_features = test['lemmatized_query']\n",
                "train_labels = train['sku']\n",
                "test_labels = test['sku']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vectorize the text data\n",
                "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
                "train_features = vectorizer.fit_transform(train_features)\n",
                "test_features = vectorizer.transform(test_features)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train Model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### RandomForestClassifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the RandomForestClassifier\n",
                "model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
                "model.fit(train_features, train_labels)\n",
                "predictions = model.predict(test_features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "d:\\College_Work\\Project\\Xbox_Prediction\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracy: 0.6253983240882804\n",
                        "Cross-validation scores: [0.63165659 0.63416433 0.6277663  0.62555326 0.63027442]\n"
                    ]
                }
            ],
            "source": [
                "# Evaluate the model\n",
                "accuracy = accuracy_score(test_labels, predictions)\n",
                "scores = cross_val_score(model, train_features, train_labels, cv=5)\n",
                "print(f\"Accuracy: {accuracy}\")\n",
                "print(f\"Cross-validation scores: {scores}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optimal Hyperparameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform Grid Search for hyperparameter tuning\n",
                "parameters = {\n",
                "    'n_estimators': [50, 100, 200],\n",
                "    'max_depth': [None, 10, 20, 30],\n",
                "    'min_samples_split': [2, 5, 10],\n",
                "    'min_samples_leaf': [1, 2, 4]\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "d:\\College_Work\\Project\\Xbox_Prediction\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "# Perform Grid Search for hyperparameter tuning with parameters\n",
                "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), parameters, cv=5, n_jobs=-1, verbose=2)\n",
                "grid_search.fit(train_features, train_labels)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the best model from grid search\n",
                "best_model = grid_search.best_estimator_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Best parameters: {grid_search.best_params_}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rf_model = RandomForestClassifier(n_estimators=200, max_depth = None, min_samples_leaf=1, min_samples_split=10, random_state=42)\n",
                "rf_model.fit(train_features, train_labels)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions with the best model\n",
                "best_predictions = rf_model.predict(test_features)\n",
                "best_accuracy = accuracy_score(test_labels, best_predictions)\n",
                "best_scores = cross_val_score(rf_model, train_features, train_labels, cv=5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute precision, recall, and F1-score\n",
                "report = classification_report(test_labels,best_predictions,output_dict=True)\n",
                "print(\"Classification Report:\\n\", report)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Debugging: Print the structure of the classification report\n",
                "print(\"\\nClassification Report Structure:\\n\", report)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract precision, recall, and F1-score\n",
                "precision = report['weighted avg']['precision']\n",
                "recall = report['weighted avg']['recall']\n",
                "f1_score = report['weighted avg']['f1-score']\n",
                "\n",
                "print(f\"Precision: {precision}\")\n",
                "print(f\"Recall: {recall}\")\n",
                "print(f\"F1-Score: {f1_score}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Best Model Accuracy: {best_accuracy}\")\n",
                "print(f\"Best Model Cross-validation scores: {best_scores}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### LogisticRegression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.preprocessing import LabelEncoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract features and labels\n",
                "features = train_data['lemmatized_query']\n",
                "labels = train_data['sku']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode the target labels\n",
                "label_encoder = LabelEncoder()\n",
                "labels_encoded = label_encoder.fit_transform(labels)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split the data\n",
                "train_features, test_features, train_labels_encoded, test_labels_encoded = train_test_split(\n",
                "    features, labels_encoded, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vectorize the text data\n",
                "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
                "train_features = vectorizer.fit_transform(train_features)\n",
                "test_features = vectorizer.transform(test_features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the LogisticRegression model\n",
                "lr_model = LogisticRegression(random_state=42, max_iter=1000)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr_model.fit(train_features, train_labels_encoded)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions with the best model\n",
                "lr_predictions = lr_model.predict(test_features)\n",
                "lr_accuracy = accuracy_score(test_labels_encoded,lr_predictions)\n",
                "lr_scores = cross_val_score(lr_model, train_features, train_labels_encoded, cv=5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"LogisticRegression Model Accuracy: {lr_accuracy}\")\n",
                "print(f\"LogisticRegression Model Cross-validation scores: {lr_scores}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ensure the classification report aligns with the predicted classes\n",
                "unique_labels = np.unique(test_labels_encoded)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute precision, recall, and F1-score\n",
                "report = classification_report(test_labels_encoded, lr_predictions, labels=unique_labels, target_names=label_encoder.classes_[unique_labels], output_dict=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Debugging: Print the structure of the classification report\n",
                "print(\"\\nClassification Report Structure:\\n\", report)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract precision, recall, and F1-score\n",
                "precision = report['weighted avg']['precision']\n",
                "recall = report['weighted avg']['recall']\n",
                "f1_score = report['weighted avg']['f1-score']\n",
                "\n",
                "print(f\"Precision: {precision}\")\n",
                "print(f\"Recall: {recall}\")\n",
                "print(f\"F1-Score: {f1_score}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
